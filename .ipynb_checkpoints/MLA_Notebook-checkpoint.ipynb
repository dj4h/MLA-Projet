{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efec2cdd",
   "metadata": {},
   "source": [
    "# Projet MLA\n",
    "## EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91a799b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\MLA\\multiDataEval.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# multi_dataset_protocol.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%run multiDataEval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96559494",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "#### Entrainement de 2 mod√®les simples\n",
    "- Mod√®le normal, entrain√© sur MNIST clean\n",
    "- Mod√®le *adversarial*, adv. training --> g√©n√®re adv. examples, mix clean+adv, mod√®le robuste\n",
    "\n",
    "![](clean_adv_diff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5e7a5",
   "metadata": {},
   "source": [
    "#### Analyse des r√©sultats\n",
    "- \"Base\" model\n",
    "    - Clean accuracy = 98%\n",
    "    - Adv accuracy = 5-20% (perf d√©truites par FGSM)\n",
    "- \"adv\" model\n",
    "    - Clean accuracy = 96-98% (l√©g√®re baisse)\n",
    "    - Adv accuracy = 90-93% (robuste ++)\n",
    "![](comparaison_performances.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04e177",
   "metadata": {},
   "source": [
    "## Attaque PGD sur MNIST\n",
    "\n",
    "![](clean_adv_diff.png)\n",
    "\n",
    "![](pgd_attack_MNIST.png)\n",
    "\n",
    "Code couleur pour la diff√©rence, directions d‚Äôam√©lioration donn√©es par le gradient\n",
    "- rouge : gradient positif (augmenter le pixel)\n",
    "- bleu : gradient n√©gatif (diminuer le pixel)\n",
    "- blanc : gradient nul\n",
    "\n",
    "La visualisation du gradient met en √©vidence les r√©gions de l‚Äôimage les plus sensibles pour le mod√®le ainsi que les directions dans lesquelles les pixels doivent √™tre modifi√©s pour augmenter la perte.\n",
    "Les zones rouges et bleues, concentr√©es sur les traits du chiffre, montrent que le r√©seau repose sur des motifs locaux pr√©cis, tandis que les zones blanches indiquent des pixels peu informatifs.\n",
    "Ces cartes de gradient fournissent une interpr√©tation directe du fonctionnement des attaques adversariales comme FGSM et PGD.\n",
    "\n",
    "FGSM applique une perturbation uniforme √† partir du signe du gradient alors que PGD affiine la perturbation √©tape par √©tape --> ins√©rer formules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c14d8e5",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "#### Objectifs\n",
    "1. Performance pure\n",
    "    - Quelle est la capacit√© brute du mod√®le √† bien classifier chaque dataset ?\n",
    "2. Robustesse, r√©sistance aux attaques adversariales\n",
    "    - Dans quelle mesure une petite perturbation suffit-elle √† tromper le mod√®le ?\n",
    "3. G√©n√©ralisation, capacit√© √† fonctionner hors distribution)\n",
    "    - Ce que le mod√®le apprend sur un dataset est-il transf√©rable ?\n",
    "4. Fiabilit√©, stabilit√© des pr√©dictions\n",
    "    - Le mod√®le est-il stable face √† de petites variations non malveillantes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f2cc4",
   "metadata": {},
   "source": [
    "## 1. Performance pure\n",
    "La performance pure est mesur√©e par :\n",
    "- Accuracy (taux de classification correcte)\n",
    "- F1-score macro (robuste aux d√©s√©quilibres de classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d60229b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_model_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1280/290097142.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m clean_acc, clean_f1 = test_model_clean(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_f1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy (clean): {clean_acc:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_model_clean' is not defined"
     ]
    }
   ],
   "source": [
    "clean_acc, clean_f1 = test_model_clean(\n",
    "    model, test_loader, device, return_f1=True\n",
    ")\n",
    "\n",
    "print(f\"Accuracy (clean): {clean_acc:.4f}\")\n",
    "print(f\"F1-score (macro): {clean_f1:.4f}\")\n",
    "\n",
    "# Une forte accuracy combin√©e √† un F1-score √©lev√© indique :\n",
    "# - une bonne capacit√© d‚Äôapprentissage\n",
    "# - une performance homog√®ne entre classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae79880",
   "metadata": {},
   "source": [
    "## 2. Robustesse adversariale\n",
    "Nous √©valuons la robustesse face √† :\n",
    "- FGSM (attaque rapide)\n",
    "- PGD (attaque it√©rative plus forte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef40fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation FGSM\n",
    "fgsm_acc = test_model_adversarial(\n",
    "    model, test_loader, epsilon, device\n",
    ")\n",
    "\n",
    "print(f\"FGSM accuracy (Œµ={epsilon}): {fgsm_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ce5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation PGD\n",
    "pgd_acc = test_model_adversarial_pgd(\n",
    "    model, test_loader,\n",
    "    epsilon=epsilon,\n",
    "    alpha=epsilon/10,\n",
    "    num_iter=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"PGD accuracy: {pgd_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e4252",
   "metadata": {},
   "source": [
    "- La chute de performance sous FGSM montre la sensibilit√© locale du mod√®le\n",
    "- PGD repr√©sente une attaque plus r√©aliste et plus dangereuse\n",
    "- Un mod√®le robuste conserve une accuracy significative sous PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b8ef2",
   "metadata": {},
   "source": [
    "### 3. Fiabilit√©\n",
    "#### Prod√©dure\n",
    "1. Ajout de bruit al√©atoire\n",
    "2. Transformations avec torchvision.transforms\n",
    "3. Analyse de stabilit√©\n",
    "    - combien de pr√©dictions changent ?\n",
    "    - confidence du softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da256513",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_acc = test_model_noise(\n",
    "    model, test_loader, sigma=0.1, device=device\n",
    ")\n",
    "\n",
    "print(f\"Accuracy under Gaussian noise: {noise_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab1950",
   "metadata": {},
   "source": [
    "Une faible d√©gradation sous bruit indique :\n",
    "- une bonne stabilit√© des repr√©sentations internes\n",
    "- une meilleure fiabilit√© en conditions r√©elles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77001a8a",
   "metadata": {},
   "source": [
    "## G√©n√©ralisation multi-datasets\n",
    "Le m√™me protocole est appliqu√© √† :\n",
    "- MNIST\n",
    "- Fashion-MNIST\n",
    "- CIFAR-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc175fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = overall_results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a81889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison clean vs adv training\n",
    "for dataset, res in results.items():\n",
    "    print(f\"\\n{dataset}\")\n",
    "    print(f\" Clean ‚Üí FGSM: {res['fgsm']:.3f}, PGD: {res['pgd']:.3f}\")\n",
    "    print(f\" Adv   ‚Üí FGSM: {res['adv_fgsm']:.3f}, PGD: {res['adv_pgd']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcea815",
   "metadata": {},
   "source": [
    "L‚Äôadversarial training :\n",
    "- am√©liore fortement la robustesse\n",
    "- d√©grade parfois l√©g√®rement la performance clean\n",
    "‚Üí compromis robustesse / performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9162a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- La performance pure ne garantit pas la robustesse\n",
    "- PGD est un test critique indispensable\n",
    "- L‚Äôadversarial training am√©liore la robustesse au prix d‚Äôune l√©g√®re perte clean\n",
    "- La g√©n√©ralisation multi-datasets est essentielle pour valider la fiabilit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3011b",
   "metadata": {},
   "source": [
    "# Brouillon\n",
    "## Param√®tres √† faire varier pour √©tudier la robustesse et la fiabilit√©\n",
    "|**Param√®tre |Effet attendu  / Ce que √ßa teste** |\n",
    "|----------|----------------------------------|\n",
    "|**Epsilon (FGSM / adversarial attack)**|Intensit√© de perturbation ‚Üí robustesse du mod√®le aux attaques|\n",
    "|**Alpha dans adversarial training**|Poids entre loss clean et loss adversarial ‚Üí impact sur trade-off clean vs robust accuracy|\n",
    "|**Batch size**|Influence la convergence et stabilit√© de l‚Äôentra√Ænement|\n",
    "|**Learning rate**|Trop grand ‚Üí mod√®le instable, trop petit ‚Üí apprentissage lent|\n",
    "|**Nombre d‚Äô√©poques**|V√©rifier si le mod√®le sur-entra√Æne ou sous-entra√Æne|\n",
    "|**Architecture du mod√®le (nombres de filtres, couches, FC)**|\tTeste si plus complexe = meilleure robustesse ou sur-apprentissage\n",
    "|**Type d‚Äôattaque (FGSM, PGD, DeepFool, etc.)**|Teste la robustesse face √† diff√©rentes perturbations|\n",
    "|**Ajout de bruit al√©atoire / transformations**|Data augmentation pour tester g√©n√©ralisation et fiabilit√© sur images l√©g√®rement modifi√©es|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878a2af",
   "metadata": {},
   "source": [
    "## √âvaluation du mod√®le sur d'autres base de donn√©es\n",
    "\n",
    "### Pourquoi?\n",
    "Dans la 1√®re partie on a pu r√©impl√©menter les √©tapes de constructions du mod√®le d√©crit dans l'article. √Ä partir de la base de donn√©e MNIST de PyTorch, le mod√®le a pu √™tre entra√Æn√© pour √©tablir la m√©thode d'entra√Ænement adversarial la plus adapt√©e au traitement de ces donn√©es. \n",
    "Toutefois, nous sommes en doit de nous demander :\n",
    "- Que vaut notre mod√®le sur une base de donn√©e alternative?\n",
    "- De quelle mani√®re pourroins nous am√©liorer les performances de notre mod√®le en l'entrainant sur d'autres bases de donn√©es ?\n",
    "\n",
    "### Bases de donn√©es accessibles avec PyTorch\n",
    "- MNIST, sur laquelle est entra√Æn√© le mod√®le\n",
    "- Fashion-MNIST, 28√ó28 - grayscale\t10 (v√™tements)\tTest de g√©n√©ralisation sur donn√©es visuelles plus vari√©es que MNIST \n",
    "- CIFAR-10\t32√ó32, RGB\t10\tImages naturelles, animaux et v√©hicules\n",
    "- CIFAR-100\t32√ó32, RGB\t100\tClassification plus fine, test de capacit√© √† g√©rer plus de classes\n",
    "- SVHN (Street View House Numbers)\t32√ó32, RGB\t10\tReconnaissance de chiffres dans des contextes r√©els\n",
    "- MNIST-M\t28√ó28, RGB\t10\tMNIST modifi√© avec bruit / background ‚Üí test de robustesse\n",
    "\n",
    "#### Mention sp√©ciale pour les datasets Kaggle\n",
    "- Custom datasets\tVariable\tVariable\tImages m√©dicales, industrielles, etc.\n",
    "\n",
    "### Crit√®re de choix\n",
    "- **MNIST / Fashion-MNIST**\n",
    "    - Simple, rapide, parfait pour tester un mod√®le de base\n",
    "- **CIFAR / SVHN**\n",
    "    - Images color√©es plus complexes ‚Üí test de capacit√© √† extraire des features plus fines\n",
    "- **MNIST-M / datasets bruit√©s** \n",
    "    - Tester la robustesse aux perturbations et aux adversarial examples\n",
    "- **Datasets custom**\n",
    "    - Tester la fiabilit√© dans un contexte r√©el ou industriel\n",
    "\n",
    "### Adaptation du mod√®le en fonction des **objectifs** :\n",
    "- G√©n√©ralisation vs robustesse\n",
    "- T√¢che simple vs t√¢che complexe\n",
    "- Grayscale vs RGB\n",
    "\n",
    "### Quel serait le protocole le plus pertinent pour √©tudier les limites de notre mod√®le et am√©liorer ses performances en l'entrainant sur diff√©rentes bases de donn√©es?\n",
    "\n",
    "#### D√©finir les objectifs\n",
    "\n",
    "Avant tout, ce que tu veux mesurer :\n",
    "\n",
    "- Robustesse : comment le mod√®le r√©siste aux attaques adversariales ou aux perturbations.\n",
    "- G√©n√©ralisation : performance sur des donn√©es nouvelles / diff√©rentes de l‚Äôentra√Ænement.\n",
    "- Fiabilit√© : stabilit√© des pr√©dictions en pr√©sence de bruit, transformations ou variations dans les donn√©es.\n",
    "- Performance pure : pr√©cision (accuracy), F1-score, etc. sur diff√©rentes bases\n",
    "\n",
    "#### Choisir les datasets\n",
    "\n",
    "S√©lectionner plusieurs bases de donn√©es, avec des caract√©ristiques vari√©es :\n",
    "\n",
    "- Simples et proches de MNIST : MNIST, Fashion-MNIST ‚Üí test de base et d√©bogage rapide.\n",
    "- Images color√©es / plus complexes : CIFAR-10/100, SVHN ‚Üí test de g√©n√©ralisation et capacit√© du mod√®le √† extraire des features complexes.\n",
    "- Variantes bruit√©es / perturb√©es : MNIST-M, datasets augment√©s ‚Üí tester robustesse.\n",
    "- Custom / r√©elles : images m√©dicales, industrielles ‚Üí tester fiabilit√© et applicabilit√© r√©elle.\n",
    "\n",
    "#### Adapter le mod√®le\n",
    "\n",
    "- Ajuster entr√©e et sortie : nombre de canaux (grayscale ‚Üí RGB), taille d‚Äôimage, nombre de classes.\n",
    "\n",
    "- √âventuellement modifier l‚Äôarchitecture si le dataset est plus complexe : plus de filtres, couches, dropout, batch normalization.\n",
    "\n",
    "#### D√©finir les protocoles d‚Äôentra√Ænement\n",
    "\n",
    "Pour chaque dataset :\n",
    "1. Mode standard (clean)\n",
    "    - Entra√Æner le mod√®le sur donn√©es clean.\n",
    "    - Tester sur donn√©es clean et adversariales.\n",
    "2. Mode adversarial training\n",
    "    - G√©n√©rer adversarial examples (FGSM, PGD, etc.)\n",
    "    - Combiner loss clean et loss adversarial (alpha * clean + (1-alpha) * adv)\n",
    "    - Tester sur clean, adversarial, et √©ventuellement sur bruit/noise.\n",
    "3. Data augmentation / bruit\n",
    "    - Rotation, translation, scaling, bruit gaussien\n",
    "    - V√©rifier si la performance et la robustesse s‚Äôam√©liorent.\n",
    "\n",
    "#### Faire varier les bons param√®tres\n",
    "Pour chaque dataset, exp√©rimenter avec :\n",
    "\n",
    "|Param√®tre|\tObjectif|\n",
    "|-------------|--------------------------------|\n",
    "|Learning rate|Tester stabilit√© et vitesse d‚Äôapprentissage|\n",
    "|Batch size\t|Impact sur convergence et r√©gularisation|\n",
    "|Epsilon (FGSM/PGD)\t|Mesurer robustesse face √† perturbations|\n",
    "|Alpha adversarial\t|Trade-off clean vs robust accuracy|\n",
    "|Architecture\t|Nombre de filtres, couches ‚Üí capacit√© du mod√®le|\n",
    "|Nombre d‚Äô√©poques\t|Sur- ou sous-entra√Ænement|\n",
    "|Augmentation / bruit\t|G√©n√©ralisation et fiabilit√©|\n",
    "\n",
    "#### √âvaluation syst√©matique\n",
    "\n",
    "Pour chaque exp√©rience, mesurer :\n",
    "- Accuracy / Loss sur clean et adversarial\n",
    "- Courbes d‚Äôapprentissage (train/test loss vs epochs)\n",
    "- Comparaison graphique des mod√®les (clean vs adversarial)\n",
    "- Visualisation des adversarial examples et des perturbations\n",
    "- Analyse des erreurs : quelles classes sont les plus fragiles ?\n",
    "\n",
    "#### Comparaison inter-datasets\n",
    "\n",
    "- Observer comment le mod√®le r√©agit √† diff√©rents types de donn√©es.\n",
    "- Identifier les datasets ou les conditions qui r√©duisent les performances.\n",
    "- Tester transfert de connaissances : entra√Æner sur dataset A, tester sur dataset B ‚Üí mesure de la g√©n√©ralisation.\n",
    "\n",
    "#### Am√©lioration it√©rative\n",
    "\n",
    "√Ä partir des observations :\n",
    "- Ajouter des couches, dropout, batch normalization pour plus de robustesse.\n",
    "- Ajuster alpha, epsilon pour adversarial training optimal.\n",
    "- Ajouter augmentation ou r√©gularisation pour mieux g√©n√©raliser.\n",
    "- R√©p√©ter le protocole sur plusieurs datasets pour confirmer la robustesse et fiabilit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5375489",
   "metadata": {},
   "source": [
    "### Adaptation du code MNIST √† un entrainement multidatasets\n",
    "\n",
    "- Adaptation de fgsm_attack : \n",
    "    - D√©tacher le tenseur et en cr√©er un nouveau avec grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d344c5a",
   "metadata": {},
   "source": [
    "### Fashion-MNIST\n",
    "##### Entrainement de 2 mod√®les simples\n",
    "- Mod√®le normal, entrain√© sur Fashion-MNIST clean\n",
    "- Mod√®le *adversarial*, adv. training --> g√©n√®re adv. examples, mix clean+adv, mod√®le robuste\n",
    "\n",
    "![](clean_adv_diff-Fashion-MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfef8a",
   "metadata": {},
   "source": [
    "#### Analyse des r√©sultats\n",
    "- \"Base\" model\n",
    "    - Clean accuracy = 88%\n",
    "    - Adv accuracy = 0.09-0.26% (perf d√©truites par FGSM)\n",
    "- \"adv\" model\n",
    "    - Clean accuracy = 85-86% (l√©g√®re baisse)\n",
    "    - Adv accuracy = 78-85% (robuste ++)\n",
    "![](comparaison_performances-Fashion-MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbe477",
   "metadata": {},
   "source": [
    "### CIFAR-10\n",
    "##### Entrainement de 2 mod√®les simples\n",
    "- Mod√®le normal, entrain√© sur CIFAR-10 clean\n",
    "- Mod√®le *adversarial*, adv. training --> g√©n√®re adv. examples, mix clean+adv, mod√®le robuste\n",
    "\n",
    "![](clean_adv_diff_CIFAR-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35020ff4",
   "metadata": {},
   "source": [
    "#### Analyse des r√©sultats\n",
    "- \"Base\" model\n",
    "    - Clean accuracy = 56-58%\n",
    "    - Adv accuracy = 0.23-44% (perf d√©truites par FGSM)\n",
    "- \"adv\" model\n",
    "    - Clean accuracy = 45% (l√©g√®re baisse)\n",
    "    - Adv accuracy = 54% (robuste ++)\n",
    "![](comparaison_performances_CIFAR-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcdaca",
   "metadata": {},
   "source": [
    "# Lien avec le cours\n",
    "On travail avec CNN => class SimpleCNN(nn.Module)\n",
    "- exploite la localit√© (bords, formes)\n",
    "- partage des poids\n",
    "- champ r√©ceptif progressif\n",
    "\n",
    "### Notre mod√®le est une version simplifi√©e de LeNet-5\n",
    "        Convolution\tnn.Conv2d\n",
    "    Activation tanh\tReLU\n",
    "    Average pooling\tMaxPool2d\n",
    "    Fully connected\tnn.Linear\n",
    "              MNIST\tMNIST\n",
    "mm principe architectural\n",
    "\n",
    "### Padding pour pr√©server l‚Äôinformation des bords\n",
    "- Padding = 1 ‚Üí \"same convolution\"\n",
    "- La taille reste 28√ó28\n",
    "\n",
    "### Augmentation du champ r√©ceptif effectif\n",
    "- Pooling = stride indirect\n",
    "- Fen√™tre 2√ó2\n",
    "- Stride = 2\n",
    "- Taille divis√©e par 2 ‚Üí 14√ó14\n",
    "Un neurone profond ne regarde plus un pixel, mais une zone √©tendue de l‚Äôimage.\n",
    "\n",
    "### MLP en fin de r√©seau\n",
    "\"self.fc1 = nn.Linear(64 * 14 * 14, 128)\"\n",
    "\"self.fc2 = nn.Linear(128, 10)\"\n",
    "- Le CNN extrait des features visuelles\n",
    "- Le MLP :\n",
    "    - combine ces features\n",
    "    - fait la d√©cision finale\n",
    "\n",
    "CNN = extracteur\n",
    "MLP = classifieur\n",
    "\n",
    "### Pourquoi le CNN est vuln√©rable ?\n",
    "\n",
    "Parce que :\n",
    "- il agr√®ge beaucoup d‚Äôinformations locales\n",
    "- une petite perturbation pixel par pixel\n",
    "- se propage dans tout le r√©seau\n",
    "PGD est plus fort que FGSM car :\n",
    "- il exploite progressivement le gradient\n",
    "- il reste dans la boule Œµ\n",
    "- il cible les zones sensibles du champ r√©ceptif\n",
    "\n",
    "### Pourquoi l‚Äôadversarial training am√©liore la robustesse ?\n",
    "loss = alpha * loss_clean + (1 - alpha) * loss_adv\n",
    "\n",
    "On force le CNN √† :\n",
    "- apprendre des features plus stables\n",
    "- r√©duire la sensibilit√© aux micro-variations\n",
    "- lisser la fonction de d√©cision\n",
    "Conceptuellement, on modifie la g√©om√©trie de l‚Äôespace des features\n",
    "\n",
    "### R√©sum√© conceptuel \n",
    "       Concept th√©orique  O√π il appara√Æt dans ton code\n",
    "                    CNN\tConv2d, MaxPool2d\n",
    "                LeNet-5\tArchitecture globale\n",
    "                    MLP\tLinear\n",
    "         Champ r√©ceptif\tEmpilement conv + pooling\n",
    "    Stride / Padding       Param√®tres des conv / pool\n",
    "        Backpropagation\tloss.backward()\n",
    "               Gradient    FGSM / PGD\n",
    "            Robustesse     Adversarial training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92065f",
   "metadata": {},
   "source": [
    "## Am√©lioration du code et lien avec le cours\n",
    "\n",
    "### Auto-encodeurs : d√©fense et interpr√©tation adversariale\n",
    "#### Id√©e cl√©\n",
    "Utiliser un auto-encodeur comme filtre de reconstruction avant le classifieur.\n",
    "\n",
    "#### Hypoth√®se :\n",
    "Les perturbations adversariales sont souvent haute fr√©quence et non naturelles.\n",
    "Un auto-encodeur entra√Æn√© sur des images propres peut les att√©nuer.\n",
    "\n",
    "- pas besoin de changer le CNN, seulement de pr√©traiter l‚Äôentr√©e\n",
    "\n",
    "#### √âtude\n",
    "- Accuracy clean vs FGSM vs PGD avec et sans auto-encodeur\n",
    "- Impact de Œµ avant / apr√®s reconstruction\n",
    "- Visualisation :\n",
    "    - image originale\n",
    "    - image adversariale\n",
    "    - image reconstruite\n",
    "    - diff√©rence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dae45b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1280/662932144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         self.encoder = nn.Sequential(\n\u001b[0;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 16x14x14\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# entra√Æner uniquement sur images clean\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 16x14x14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 32x7x7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √©valuation, dans test FGSM / PGD\n",
    "with torch.no_grad():\n",
    "    x_recon = autoencoder(x_adv)\n",
    "    output = model(x_recon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc8ad2",
   "metadata": {},
   "source": [
    "#### MNIST / Fashion-MNIST\n",
    "- Tr√®s pertinent\n",
    "- Reconstruction facile\n",
    "- Perturbations adversariales bien visibles\n",
    "L‚Äôauto-encodeur agit comme un filtre basse fr√©quence efficace\n",
    "\n",
    "Conclusion : am√©lioration claire de la robustesse FGSM, parfois PGD l√©ger.\n",
    "\n",
    "#### CIFAR-10\n",
    "- pruning mod√©r√© utile\n",
    "- trop de pruning ‚Üí chute clean + robuste\n",
    "int√©ressant pour montrer un compromis capacit√© / robustesse\n",
    "\n",
    "Les mod√®les surparam√©tr√©s sont souvent plus vuln√©rables aux attaques locales.\n",
    "\n",
    "    D√©fense\tMNIST\tCIFAR-10\n",
    "    FGSM training\t‚úî\t‚úî\n",
    "    AE preprocessing\t‚úî‚úî\t‚ö†Ô∏è\n",
    "    Pruning\t‚úî\t‚úî\n",
    "    PGD robustness\t‚ùå\t‚ùå\n",
    "Aucune d√©fense simple ne g√©n√©ralise parfaitement. La robustesse d√©pend √† la fois du mod√®le, de la d√©fense et de la structure du dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba9fa1",
   "metadata": {},
   "source": [
    "### Auto-encodeur = compression de l‚Äôinformation\n",
    "\n",
    "Tu peux aussi pr√©senter l‚ÄôAE comme une compression non lin√©aire de l‚Äôimage\n",
    "\n",
    "üîç Lien direct avec la robustesse\n",
    "- Compression ‚áí perte d‚Äôinformation fine\n",
    "- Les perturbations adversariales sont souvent tr√®s fines\n",
    "- Donc elles sont √©cras√©es par la compression\n",
    "\n",
    "üëâ Tu peux faire varier :\n",
    "- taille du latent space\n",
    "- taux de compression\n",
    "Et mesurer :\n",
    "- accuracy clean\n",
    "- accuracy FGSM / PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6db3d",
   "metadata": {},
   "source": [
    "### Compression du r√©seau (pruning & quantization)\n",
    "üí° Pourquoi c‚Äôest pertinent ici ?\n",
    "Il existe un lien fort entre :\n",
    "- complexit√© du mod√®le\n",
    "- sensibilit√© aux perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dfd635",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1280/1935181862.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Pruning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m prune.l1_unstructured(\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Pruning\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "prune.l1_unstructured(\n",
    "    model.fc1,\n",
    "    name=\"weight\",\n",
    "    amount=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc0a7e",
   "metadata": {},
   "source": [
    "comparer :\n",
    "- mod√®le dense\n",
    "- mod√®le prun√©\n",
    "- robustesse FGSM / PGD\n",
    "\n",
    "#### Hypoth√®se int√©ressante\n",
    "\n",
    "Un mod√®le plus simple peut parfois √™tre moins sensible aux perturbations locales\n",
    "\n",
    "(ce n‚Äôest pas toujours vrai ‚Üí tr√®s bon point de discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70237e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
