{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7585309-4749-4b5f-8e0b-2c74bffc5a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation des centres RBF via K-Means (peut prendre quelques secondes)...\n",
      "Entraînement du RBF...\n",
      "Terminé.\n",
      "\n",
      "Accuracy sur le dataset de test MNIST (clean) : 93.94%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mclamp(images \u001b[38;5;241m+\u001b[39m eps \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39msign(), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Clean\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m out_clean \u001b[38;5;241m=\u001b[39m model_rbf(\u001b[43mbatch_x\u001b[49m)\n\u001b[1;32m    129\u001b[0m correct_clean \u001b[38;5;241m=\u001b[39m (out_clean\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m batch_y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Attaque FGSM\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_x' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "EPSILON = 0.25  # Même force que pour les tests précédents\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DÉFINITION DU RÉSEAU RBF (Non-Linéaire)\n",
    "# ============================================================================\n",
    "class RBF_Layer(nn.Module):\n",
    "    def __init__(self, in_features, num_centers):\n",
    "        super(RBF_Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.num_centers = num_centers\n",
    "        \n",
    "        # Les \"Centres\" (prototypes) et \"Sigmas\" (largeur de la cloche)\n",
    "        self.centers = nn.Parameter(torch.Tensor(num_centers, in_features))\n",
    "        self.sigmas = nn.Parameter(torch.Tensor(num_centers))\n",
    "        \n",
    "        # Initialisation aléatoire avant K-Means\n",
    "        nn.init.normal_(self.centers, 1)\n",
    "        nn.init.constant_(self.sigmas,1 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Calcul de la distance Euclidienne ||x - c||\n",
    "        # x: (batch, features), centers: (centers, features)\n",
    "        x = x.unsqueeze(1) # (batch, 1, features)\n",
    "        c = self.centers.unsqueeze(0) # (1, centers, features)\n",
    "        \n",
    "        # Distance au carré\n",
    "        dist_sq = ((x - c) ** 2).sum(dim=2)\n",
    "        \n",
    "        # Fonction Gaussienne : exp(-dist^2 / 2*sigma^2)\n",
    "        # C'est purement non-linéaire (en forme de cloche)\n",
    "        return torch.exp(-dist_sq / (2 * self.sigmas.pow(2) + 1e-8))\n",
    "\n",
    "class RBFNet(nn.Module):\n",
    "    def __init__(self, num_centers=100):\n",
    "        super(RBFNet, self).__init__()\n",
    "        self.rbf = RBF_Layer(784, num_centers)\n",
    "        self.linear = nn.Linear(num_centers, 10) # Couche de sortie simple\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.rbf(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. PRÉPARATION & ENTRAÎNEMENT\n",
    "# ============================================================================\n",
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Initialisation Intelligente (K-Means) ---\n",
    "# Les RBF apprennent mal si les centres sont aléatoires. On utilise K-Means sur une partie des données.\n",
    "print(\"Initialisation des centres RBF via K-Means (peut prendre quelques secondes)...\")\n",
    "data_sample = next(iter(DataLoader(trainset, batch_size=5000, shuffle=True)))[0].view(5000, -1).numpy()\n",
    "kmeans = KMeans(n_clusters=100, n_init=10).fit(data_sample)\n",
    "\n",
    "model_rbf = RBFNet(num_centers=100).to(DEVICE)\n",
    "# On copie les centres trouvés par K-Means dans le modèle\n",
    "model_rbf.rbf.centers.data = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32).to(DEVICE)\n",
    "# On fixe un sigma initial raisonnable\n",
    "model_rbf.rbf.sigmas.data.fill_(1.5)\n",
    "\n",
    "optimizer = optim.Adam(model_rbf.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Entraînement du RBF...\")\n",
    "model_rbf.train()\n",
    "for epoch in range(5):\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_rbf(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Terminé.\")\n",
    "\n",
    "# ÉVALUATION SUR LE DATASET DE TEST MNIST (CLEAN)\n",
    "# ============================================================================\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in testloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        outputs = model_rbf(x)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct_test += (preds == y).sum().item()\n",
    "        total_test += y.size(0)\n",
    "\n",
    "accuracy_test = correct_test / total_test\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de test MNIST (clean) : {accuracy_test*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. TESTS DE RÉSISTANCE (FGSM & RUBBISH)\n",
    "# ============================================================================\n",
    "def fgsm_attack(model, images, labels, eps):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    return torch.clamp(images + eps * images.grad.sign(), 0, 1)\n",
    "\n",
    "# Clean\n",
    "out_clean = model_rbf(batch_x)\n",
    "correct_clean = (out_clean.argmax(1) == batch_y).sum().item()\n",
    "\n",
    "# Attaque FGSM\n",
    "adv_x = fgsm_attack(model_rbf, batch_x, batch_y, EPSILON)\n",
    "out_adv = model_rbf(adv_x)\n",
    "correct_adv = (out_adv.argmax(1) == batch_y).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ÉVALUATION SUR LE DATASET DE TRAIN MNIST AVEC ATTAQUE FGSM\n",
    "# ============================================================================\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_train_fgsm = 0\n",
    "total_train_fgsm = 0\n",
    "\n",
    "for x, y in trainloader:\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    # Génération des exemples adversariaux FGSM\n",
    "    x_adv = fgsm_attack(model_rbf, x, y, EPSILON)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_rbf(x_adv)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "    correct_train_fgsm += (preds == y).sum().item()\n",
    "    total_train_fgsm += y.size(0)\n",
    "\n",
    "accuracy_train_fgsm = correct_train_fgsm / total_train_fgsm\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de train MNIST avec FGSM : {accuracy_train_fgsm*100:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# ÉVALUATION SUR LE DATASET DE TEST MNIST AVEC ATTAQUE FGSM\n",
    "# ============================================================================\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_test_fgsm = 0\n",
    "total_test_fgsm = 0\n",
    "\n",
    "for x, y in testloader:\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    # Génération des exemples adversariaux FGSM\n",
    "    x_adv = fgsm_attack(model_rbf, x, y, EPSILON)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_rbf(x_adv)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "    correct_test_fgsm += (preds == y).sum().item()\n",
    "    total_test_fgsm += y.size(0)\n",
    "\n",
    "accuracy_test_fgsm = correct_test_fgsm / total_test_fgsm\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de test MNIST avec FGSM : {accuracy_test_fgsm*100:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. TESTS DE RÉSISTANCE (RUBBISH CLASS - VERSION ARTICLE)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n--- 2. Test Rubbish Class (Version Article 2015) ---\")\n",
    "\n",
    "# 1. Génération de \"Gaussian Rubbish\" (Bruit pur)\n",
    "# L'article mentionne que les modèles linéaires sont trompés par du bruit gaussien\n",
    "rubbish_gaussian = torch.randn(1000, 1, 28, 28).to(DEVICE)\n",
    "rubbish_gaussian = torch.clamp(rubbish_gaussian, 0, 1) # On reste dans l'espace [0, 1]\n",
    "\n",
    "# 2. Génération de \"Fooling Images\" (Bruit + FGSM)\n",
    "# L'article explique qu'on peut forcer n'importe quelle classe à partir du bruit\n",
    "def generate_fooling_image(model, base_noise, target_class, eps=0.25):\n",
    "    temp_noise = base_noise.clone().detach().requires_grad_(True)\n",
    "    outputs = model(temp_noise)\n",
    "    \n",
    "    # On crée un faux label cible (ex: class 3)\n",
    "    target = torch.full((base_noise.size(0),), target_class, dtype=torch.long).to(DEVICE)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, target)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # On pousse le bruit vers la classe cible (Gradient Sign Descent pour la perte)\n",
    "    fooling_image = temp_noise - eps * temp_noise.grad.sign()\n",
    "    return torch.clamp(fooling_image, 0, 1)\n",
    "\n",
    "# Évaluation\n",
    "model_rbf.eval()\n",
    "with torch.no_grad():\n",
    "    # Sortie sur bruit pur\n",
    "    out_rubbish = model_rbf(rubbish_gaussian)\n",
    "    # L'article suggère que les RBF ont une activation quasi-nulle loin des données\n",
    "    # Pour un RBF, la confiance est souvent mesurée par l'intensité de l'activation avant Softmax\n",
    "    probs_rubbish = torch.softmax(out_rubbish, dim=1)\n",
    "    max_conf, preds = probs_rubbish.max(1)\n",
    "    \n",
    "    # Dans l'article, un taux d'erreur de 0% sur le rubbish signifie que le modèle\n",
    "    # ne classifie PAS ces images comme appartenant aux classes 0-9 avec confiance.\n",
    "    # On définit un seuil de rejet (ex: si conf < 0.5, on considère cela comme \"correctement rejeté\")\n",
    "    threshold = 0.5\n",
    "    correctly_rejected = (max_conf < threshold).float().mean().item()\n",
    "\n",
    "print(f\"Confiance moyenne sur bruit Gaussien : {max_conf.mean().item()*100:.2f}%\")\n",
    "print(f\"Taux de rejet (Confiance < {threshold}) : {correctly_rejected*100:.2f}%\")\n",
    "\n",
    "# Test des images \"Fooling\" (Bruit dirigé vers la classe 3)\n",
    "fooling_samples = generate_fooling_image(model_rbf, rubbish_gaussian[:100], target_class=3)\n",
    "with torch.no_grad():\n",
    "    out_fooling = model_rbf(fooling_samples)\n",
    "    conf_fooling = torch.softmax(out_fooling, dim=1).max(1)[0].mean().item()\n",
    "\n",
    "print(f\"Confiance moyenne sur 'Fooling Images' (bruit optimisé) : {conf_fooling*100:.2f}%\")\n",
    "\n",
    "print(\"\\nAnalyse selon l'article :\")\n",
    "print(\"- Un modèle Linéaire/Maxout aurait une confiance > 90% ici.\")\n",
    "print(\"- Le RBF, grâce à ses cloches de Gauss localisées, 's'éteint' dans les zones vides.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TEST DE TRANSFERT (Softmax -> RBF)\n",
    "# ============================================================================\n",
    "print(f\"\\n--- 3. Test de Transfert (Linear -> RBF) ---\")\n",
    "\n",
    "# 1. On entraîne rapidement un modèle linéaire (Softmax)\n",
    "model_linear = nn.Linear(28*28, 10).to(DEVICE)\n",
    "opt_lin = optim.SGD(model_linear.parameters(), lr=0.1)\n",
    "\n",
    "# Entraînement rapide sur quelques batchs pour avoir des poids cohérents\n",
    "model_linear.train()\n",
    "for epoch in range(2): # 2 époques suffisent pour l'attaque\n",
    "    for x, y in trainloader:\n",
    "        x = x.view(-1, 28*28).to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        loss = nn.CrossEntropyLoss()(model_linear(x), y)\n",
    "        opt_lin.zero_grad(); loss.backward(); opt_lin.step()\n",
    "\n",
    "# 2. Génération de l'attaque SUR LE MODÈLE LINÉAIRE\n",
    "# --- CORRECTION ICI ---\n",
    "# On utilise .clone().detach() pour casser le graphe et créer une \"feuille\"\n",
    "batch_x_flat = batch_x.view(-1, 28*28).clone().detach().to(DEVICE)\n",
    "batch_x_flat.requires_grad = True\n",
    "\n",
    "# Passe avant sur le modèle linéaire\n",
    "output_lin = model_linear(batch_x_flat)\n",
    "loss = nn.CrossEntropyLoss()(output_lin, batch_y)\n",
    "\n",
    "# Calcul du gradient\n",
    "model_linear.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Création de l'image adversaire (basée sur le gradient du linéaire)\n",
    "# x_adv = x + eps * sign(grad_lineaire)\n",
    "adv_transfer = torch.clamp(batch_x_flat + EPSILON * batch_x_flat.grad.sign(), 0, 1)\n",
    "adv_transfer = adv_transfer.view(-1, 1, 28, 28) # Reshape pour rentrer dans le RBF\n",
    "\n",
    "# 3. Test de cette image SUR LE RBF\n",
    "with torch.no_grad():\n",
    "    out_transfer = model_rbf(adv_transfer)\n",
    "    acc_transfer = (out_transfer.argmax(1) == batch_y).float().mean().item()\n",
    "\n",
    "print(f\"Précision du RBF sur attaques transférées du Linéaire : {acc_transfer*100:.2f}%\")\n",
    "print(\"Analyse : Si ce score est élevé (>80%), le RBF ignore les attaques conçues pour le linéaire.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133eb6d-41d8-4580-b319-d20695528fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb4cc9-1f1f-417a-a3f5-38fda2812be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ca612-13b2-4a15-a927-4723f7c258e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1cce4-1969-43da-b406-3abf0d54f4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd8e6c-6c1c-4a0d-81e7-3f5f27b5db10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85b637-3960-4248-86cb-38a9a728f91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac3d82-7992-4d5d-96a5-12e62d123b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
