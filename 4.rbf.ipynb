{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7585309-4749-4b5f-8e0b-2c74bffc5a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation des centres RBF via K-Means (peut prendre quelques secondes)...\n",
      "Entraînement du RBF...\n",
      "Terminé.\n",
      "\n",
      "Accuracy sur le dataset de test MNIST (clean) : 93.94%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mclamp(images \u001b[38;5;241m+\u001b[39m eps \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39msign(), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Clean\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m out_clean \u001b[38;5;241m=\u001b[39m model_rbf(\u001b[43mbatch_x\u001b[49m)\n\u001b[1;32m    129\u001b[0m correct_clean \u001b[38;5;241m=\u001b[39m (out_clean\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m batch_y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Attaque FGSM\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_x' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "EPSILON = 0.25  \n",
    "\n",
    "\n",
    "# 1. DÉFINITION DU RÉSEAU RBF (Non-Linéaire)\n",
    "\n",
    "class RBF_Layer(nn.Module):\n",
    "    def __init__(self, in_features, num_centers):\n",
    "        super(RBF_Layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.num_centers = num_centers\n",
    "        \n",
    "        \n",
    "        self.centers = nn.Parameter(torch.Tensor(num_centers, in_features))\n",
    "        self.sigmas = nn.Parameter(torch.Tensor(num_centers))\n",
    "        \n",
    "       \n",
    "        nn.init.normal_(self.centers, 1)\n",
    "        nn.init.constant_(self.sigmas,1 )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.unsqueeze(1) \n",
    "        c = self.centers.unsqueeze(0) \n",
    "        \n",
    "        dist_sq = ((x - c) ** 2).sum(dim=2)\n",
    "        \n",
    "        return torch.exp(-dist_sq / (2 * self.sigmas.pow(2) + 1e-8))\n",
    "\n",
    "class RBFNet(nn.Module):\n",
    "    def __init__(self, num_centers=100):\n",
    "        super(RBFNet, self).__init__()\n",
    "        self.rbf = RBF_Layer(784, num_centers)\n",
    "        self.linear = nn.Linear(num_centers, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.rbf(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "# 2. PRÉPARATION & ENTRAÎNEMENT\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Initialisation Intelligente (K-Means) ---\n",
    "print(\"Initialisation des centres RBF via K-Means (peut prendre quelques secondes)...\")\n",
    "data_sample = next(iter(DataLoader(trainset, batch_size=5000, shuffle=True)))[0].view(5000, -1).numpy()\n",
    "kmeans = KMeans(n_clusters=100, n_init=10).fit(data_sample)\n",
    "\n",
    "model_rbf = RBFNet(num_centers=100).to(DEVICE)\n",
    "\n",
    "model_rbf.rbf.centers.data = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "model_rbf.rbf.sigmas.data.fill_(1.5)\n",
    "\n",
    "optimizer = optim.Adam(model_rbf.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Entraînement du RBF...\")\n",
    "model_rbf.train()\n",
    "for epoch in range(5):\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_rbf(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Terminé.\")\n",
    "\n",
    "# ÉVALUATION SUR LE DATASET DE TEST MNIST (CLEAN)\n",
    "\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in testloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        outputs = model_rbf(x)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct_test += (preds == y).sum().item()\n",
    "        total_test += y.size(0)\n",
    "\n",
    "accuracy_test = correct_test / total_test\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de test MNIST (clean) : {accuracy_test*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. TESTS DE RÉSISTANCE (FGSM & RUBBISH)\n",
    "\n",
    "def fgsm_attack(model, images, labels, eps):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    return torch.clamp(images + eps * images.grad.sign(), 0, 1)\n",
    "\n",
    "# Clean\n",
    "out_clean = model_rbf(batch_x)\n",
    "correct_clean = (out_clean.argmax(1) == batch_y).sum().item()\n",
    "\n",
    "# Attaque FGSM\n",
    "adv_x = fgsm_attack(model_rbf, batch_x, batch_y, EPSILON)\n",
    "out_adv = model_rbf(adv_x)\n",
    "correct_adv = (out_adv.argmax(1) == batch_y).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ÉVALUATION SUR LE DATASET DE TRAIN MNIST AVEC ATTAQUE FGSM\n",
    "\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_train_fgsm = 0\n",
    "total_train_fgsm = 0\n",
    "\n",
    "for x, y in trainloader:\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    # Génération des exemples adversariaux FGSM\n",
    "    x_adv = fgsm_attack(model_rbf, x, y, EPSILON)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_rbf(x_adv)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "    correct_train_fgsm += (preds == y).sum().item()\n",
    "    total_train_fgsm += y.size(0)\n",
    "\n",
    "accuracy_train_fgsm = correct_train_fgsm / total_train_fgsm\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de train MNIST avec FGSM : {accuracy_train_fgsm*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ÉVALUATION SUR LE DATASET DE TEST MNIST AVEC ATTAQUE FGSM\n",
    "\n",
    "model_rbf.eval()\n",
    "\n",
    "correct_test_fgsm = 0\n",
    "total_test_fgsm = 0\n",
    "\n",
    "for x, y in testloader:\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "    # Génération des exemples adversariaux FGSM\n",
    "    x_adv = fgsm_attack(model_rbf, x, y, EPSILON)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_rbf(x_adv)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "    correct_test_fgsm += (preds == y).sum().item()\n",
    "    total_test_fgsm += y.size(0)\n",
    "\n",
    "accuracy_test_fgsm = correct_test_fgsm / total_test_fgsm\n",
    "\n",
    "print(f\"\\nAccuracy sur le dataset de test MNIST avec FGSM : {accuracy_test_fgsm*100:.2f}%\")\n",
    "\n",
    "\n",
    "# 3. TESTS DE RÉSISTANCE (RUBBISH CLASS - VERSION ARTICLE)\n",
    "\n",
    "print(f\"\\n--- 2. Test Rubbish Class (Version Article 2015) ---\")\n",
    "\n",
    "# 1. Génération de \"Gaussian Rubbish\" (Bruit pur)\n",
    "\n",
    "rubbish_gaussian = torch.randn(1000, 1, 28, 28).to(DEVICE)\n",
    "rubbish_gaussian = torch.clamp(rubbish_gaussian, 0, 1) \n",
    "\n",
    "# 2. Génération de \"Fooling Images\" (Bruit + FGSM)\n",
    "\n",
    "def generate_fooling_image(model, base_noise, target_class, eps=0.25):\n",
    "    temp_noise = base_noise.clone().detach().requires_grad_(True)\n",
    "    outputs = model(temp_noise)\n",
    "    \n",
    "    target = torch.full((base_noise.size(0),), target_class, dtype=torch.long).to(DEVICE)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, target)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    fooling_image = temp_noise - eps * temp_noise.grad.sign()\n",
    "    return torch.clamp(fooling_image, 0, 1)\n",
    "\n",
    "# Évaluation\n",
    "model_rbf.eval()\n",
    "with torch.no_grad():\n",
    "    # Sortie sur bruit pur\n",
    "    out_rubbish = model_rbf(rubbish_gaussian)\n",
    "\n",
    "    probs_rubbish = torch.softmax(out_rubbish, dim=1)\n",
    "    max_conf, preds = probs_rubbish.max(1)\n",
    "    \n",
    "    # On définit un seuil de rejet (ex: si conf < 0.5, on considère cela comme \"correctement rejeté\")\n",
    "    threshold = 0.5\n",
    "    correctly_rejected = (max_conf < threshold).float().mean().item()\n",
    "\n",
    "print(f\"Confiance moyenne sur bruit Gaussien : {max_conf.mean().item()*100:.2f}%\")\n",
    "print(f\"Taux de rejet (Confiance < {threshold}) : {correctly_rejected*100:.2f}%\")\n",
    "\n",
    "# Test des images \"Fooling\" (Bruit dirigé vers la classe 3)\n",
    "fooling_samples = generate_fooling_image(model_rbf, rubbish_gaussian[:100], target_class=3)\n",
    "with torch.no_grad():\n",
    "    out_fooling = model_rbf(fooling_samples)\n",
    "    conf_fooling = torch.softmax(out_fooling, dim=1).max(1)[0].mean().item()\n",
    "\n",
    "print(f\"Confiance moyenne sur 'Fooling Images' (bruit optimisé) : {conf_fooling*100:.2f}%\")\n",
    "\n",
    "print(\"\\nAnalyse selon l'article :\")\n",
    "print(\"- Un modèle Linéaire/Maxout aurait une confiance > 90% ici.\")\n",
    "print(\"- Le RBF, grâce à ses cloches de Gauss localisées, 's'éteint' dans les zones vides.\")\n",
    "\n",
    "\n",
    "# 4. TEST DE TRANSFERT (Softmax -> RBF)\n",
    "\n",
    "print(f\"\\n--- 3. Test de Transfert (Linear -> RBF) ---\")\n",
    "\n",
    "# 1. On entraîne rapidement un modèle linéaire (Softmax)\n",
    "model_linear = nn.Linear(28*28, 10).to(DEVICE)\n",
    "opt_lin = optim.SGD(model_linear.parameters(), lr=0.1)\n",
    "\n",
    "model_linear.train()\n",
    "for epoch in range(2): \n",
    "    for x, y in trainloader:\n",
    "        x = x.view(-1, 28*28).to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        loss = nn.CrossEntropyLoss()(model_linear(x), y)\n",
    "        opt_lin.zero_grad(); loss.backward(); opt_lin.step()\n",
    "\n",
    "# 2. Génération de l'attaque SUR LE MODÈLE LINÉAIRE\n",
    "\n",
    "batch_x_flat = batch_x.view(-1, 28*28).clone().detach().to(DEVICE)\n",
    "batch_x_flat.requires_grad = True\n",
    "\n",
    "# Passe avant sur le modèle linéaire\n",
    "output_lin = model_linear(batch_x_flat)\n",
    "loss = nn.CrossEntropyLoss()(output_lin, batch_y)\n",
    "\n",
    "# Calcul du gradient\n",
    "model_linear.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Cr\n",
    "adv_transfer = torch.clamp(batch_x_flat + EPSILON * batch_x_flat.grad.sign(), 0, 1)\n",
    "adv_transfer = adv_transfer.view(-1, 1, 28, 28) # Reshape pour rentrer dans le RBF\n",
    "\n",
    "# 3. Test de cette image SUR LE RBF\n",
    "with torch.no_grad():\n",
    "    out_transfer = model_rbf(adv_transfer)\n",
    "    acc_transfer = (out_transfer.argmax(1) == batch_y).float().mean().item()\n",
    "\n",
    "print(f\"Précision du RBF sur attaques transférées du Linéaire : {acc_transfer*100:.2f}%\")\n",
    "print(\"Analyse : Si ce score est élevé (>80%), le RBF ignore les attaques conçues pour le linéaire.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133eb6d-41d8-4580-b319-d20695528fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb4cc9-1f1f-417a-a3f5-38fda2812be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ca612-13b2-4a15-a927-4723f7c258e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1cce4-1969-43da-b406-3abf0d54f4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd8e6c-6c1c-4a0d-81e7-3f5f27b5db10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85b637-3960-4248-86cb-38a9a728f91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac3d82-7992-4d5d-96a5-12e62d123b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
