{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1170bb74-2286-45a7-9553-64771e63cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e73ce92-4202-4827-a14f-265947c148fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test de vulnÃ©rabilitÃ© sur un modÃ¨le convolutif maxout\n",
    "#Entrainement sur le dataset de train CIFAR10\n",
    "#Evaluation sur le dataset de test CIFAR10\n",
    "#Evaluation sur le dataset de train CIFAR10 avec modif FGSM\n",
    "#Evaluation sur le dataset de test CIFAR10 avec modif FGSM\n",
    "#Ces evaluations sont effectuÃ©es pour les optimizer SGD et Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c15091bd-8041-45b1-82e4-78950e7f7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "EntraÃ®nement sur cuda\n",
      "Epoch [1/70] | Loss 1.652 | Acc 40.23%\n",
      "Epoch [2/70] | Loss 1.244 | Acc 55.69%\n",
      "Epoch [3/70] | Loss 1.060 | Acc 62.57%\n",
      "Epoch [4/70] | Loss 0.953 | Acc 66.70%\n",
      "Epoch [5/70] | Loss 0.870 | Acc 69.74%\n",
      "Epoch [6/70] | Loss 0.811 | Acc 71.76%\n",
      "Epoch [7/70] | Loss 0.763 | Acc 73.17%\n",
      "Epoch [8/70] | Loss 0.722 | Acc 74.91%\n",
      "Epoch [9/70] | Loss 0.693 | Acc 75.85%\n",
      "Epoch [10/70] | Loss 0.670 | Acc 76.81%\n",
      "Epoch [11/70] | Loss 0.644 | Acc 77.79%\n",
      "Epoch [12/70] | Loss 0.629 | Acc 78.14%\n",
      "Epoch [13/70] | Loss 0.607 | Acc 79.00%\n",
      "Epoch [14/70] | Loss 0.592 | Acc 79.35%\n",
      "Epoch [15/70] | Loss 0.582 | Acc 79.69%\n",
      "Epoch [16/70] | Loss 0.566 | Acc 80.24%\n",
      "Epoch [17/70] | Loss 0.551 | Acc 80.82%\n",
      "Epoch [18/70] | Loss 0.539 | Acc 81.39%\n",
      "Epoch [19/70] | Loss 0.531 | Acc 81.50%\n",
      "Epoch [20/70] | Loss 0.528 | Acc 81.53%\n",
      "Epoch [21/70] | Loss 0.509 | Acc 82.25%\n",
      "Epoch [22/70] | Loss 0.506 | Acc 82.20%\n",
      "Epoch [23/70] | Loss 0.499 | Acc 82.49%\n",
      "Epoch [24/70] | Loss 0.491 | Acc 82.81%\n",
      "Epoch [25/70] | Loss 0.483 | Acc 82.95%\n",
      "Epoch [26/70] | Loss 0.477 | Acc 83.16%\n",
      "Epoch [27/70] | Loss 0.466 | Acc 83.92%\n",
      "Epoch [28/70] | Loss 0.469 | Acc 83.65%\n",
      "Epoch [29/70] | Loss 0.460 | Acc 83.85%\n",
      "Epoch [30/70] | Loss 0.454 | Acc 84.15%\n",
      "Epoch [31/70] | Loss 0.443 | Acc 84.32%\n",
      "Epoch [32/70] | Loss 0.447 | Acc 84.28%\n",
      "Epoch [33/70] | Loss 0.437 | Acc 84.78%\n",
      "Epoch [34/70] | Loss 0.441 | Acc 84.68%\n",
      "Epoch [35/70] | Loss 0.427 | Acc 85.04%\n",
      "Epoch [36/70] | Loss 0.434 | Acc 84.91%\n",
      "Epoch [37/70] | Loss 0.414 | Acc 85.54%\n",
      "Epoch [38/70] | Loss 0.419 | Acc 85.34%\n",
      "Epoch [39/70] | Loss 0.413 | Acc 85.50%\n",
      "Epoch [40/70] | Loss 0.412 | Acc 85.61%\n",
      "Epoch [41/70] | Loss 0.411 | Acc 85.49%\n",
      "Epoch [42/70] | Loss 0.408 | Acc 85.62%\n",
      "Epoch [43/70] | Loss 0.404 | Acc 85.96%\n",
      "Epoch [44/70] | Loss 0.400 | Acc 85.92%\n",
      "Epoch [45/70] | Loss 0.406 | Acc 85.71%\n",
      "Epoch [46/70] | Loss 0.398 | Acc 85.97%\n",
      "Epoch [47/70] | Loss 0.393 | Acc 86.18%\n",
      "Epoch [48/70] | Loss 0.398 | Acc 85.89%\n",
      "Epoch [49/70] | Loss 0.388 | Acc 86.34%\n",
      "Epoch [50/70] | Loss 0.393 | Acc 86.22%\n",
      "Epoch [51/70] | Loss 0.394 | Acc 86.09%\n",
      "Epoch [52/70] | Loss 0.382 | Acc 86.48%\n",
      "Epoch [53/70] | Loss 0.386 | Acc 86.66%\n",
      "Epoch [54/70] | Loss 0.381 | Acc 86.66%\n",
      "Epoch [55/70] | Loss 0.375 | Acc 86.83%\n",
      "Epoch [56/70] | Loss 0.373 | Acc 86.93%\n",
      "Epoch [57/70] | Loss 0.373 | Acc 86.80%\n",
      "Epoch [58/70] | Loss 0.381 | Acc 86.80%\n",
      "Epoch [59/70] | Loss 0.375 | Acc 86.79%\n",
      "Epoch [60/70] | Loss 0.380 | Acc 86.72%\n",
      "Epoch [61/70] | Loss 0.363 | Acc 87.18%\n",
      "Epoch [62/70] | Loss 0.372 | Acc 86.88%\n",
      "Epoch [63/70] | Loss 0.370 | Acc 87.02%\n",
      "Epoch [64/70] | Loss 0.371 | Acc 86.87%\n",
      "Epoch [65/70] | Loss 0.368 | Acc 86.93%\n",
      "Epoch [66/70] | Loss 0.367 | Acc 87.00%\n",
      "Epoch [67/70] | Loss 0.361 | Acc 87.33%\n",
      "Epoch [68/70] | Loss 0.360 | Acc 87.37%\n",
      "Epoch [69/70] | Loss 0.363 | Acc 87.13%\n",
      "Epoch [70/70] | Loss 0.361 | Acc 87.16%\n",
      "\n",
      "--- RÃ©sultats Maxout CIFAR-10 ---\n",
      "Accuracy Test Clean   : 84.32%\n",
      "Accuracy Test FGSM    : 1.98%\n",
      "Accuracy Train FGSM   : 2.35%\n",
      "\n",
      "--- Confiance moyenne sur les erreurs ---\n",
      "Confiance erreurs Test Clean : 68.76%\n",
      "Confiance erreurs Test FGSM  : 89.92%\n",
      "Confiance erreurs Train FGSM : 89.54%\n"
     ]
    }
   ],
   "source": [
    "#Optimizer SGD\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 70\n",
    "EPSILON = 0.1\n",
    "\n",
    "\n",
    "# maxout convolutionnel\n",
    "class MaxoutConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=2, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * k,\n",
    "                              kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.view(b, self.out_channels, self.k, h, w)\n",
    "        x, _ = x.max(dim=2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RealConvMaxoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = MaxoutConv2d(3, 48, k=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv2 = MaxoutConv2d(48, 96, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv3 = MaxoutConv2d(96, 192, k=2)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.drop3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc = nn.Linear(192 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.pool1(self.conv1(x)))\n",
    "        x = self.drop2(self.pool2(self.conv2(x)))\n",
    "        x = self.drop3(self.pool3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# cifar-10\n",
    "def load_data():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# training\n",
    "def train(model, trainloader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    print(f\"EntraÃ®nement sur {DEVICE}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, running_loss = 0, 0, 0.0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss {running_loss/len(trainloader):.3f} | Acc {acc:.2f}%\")\n",
    "\n",
    "\n",
    "# FGSM\n",
    "def fgsm_attack(x, epsilon, grad):\n",
    "    return x + epsilon * grad.sign()\n",
    "\n",
    "# Ã©valuation\n",
    "def mean_confidence_on_errors(model, dataloader, adversarial=False, epsilon=0.0):\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        if adversarial:\n",
    "            inputs.requires_grad = True\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            grad = inputs.grad.data\n",
    "            inputs = fgsm_attack(inputs, epsilon, grad)\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        mask = preds != labels\n",
    "        if mask.any():\n",
    "            confidences.extend(probs[mask, preds[mask]].detach().cpu().numpy())\n",
    "\n",
    "    if len(confidences) == 0:\n",
    "        return 0.0\n",
    "    return float(np.mean(confidences))\n",
    "\n",
    "# prÃ©csion\n",
    "def accuracy(model, dataloader, adversarial=False, epsilon=0.0):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        if adversarial:\n",
    "            inputs.requires_grad = True\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            inputs = fgsm_attack(inputs, epsilon, inputs.grad.data)\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return 100. * correct / total\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    trainloader, testloader = load_data()\n",
    "\n",
    "    model = RealConvMaxoutNet().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "                          momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    train(model, trainloader, optimizer, criterion, EPOCHS)\n",
    "\n",
    "    acc_test_clean = accuracy(model, testloader, adversarial=False)\n",
    "    acc_test_adv   = accuracy(model, testloader, adversarial=True, epsilon=EPSILON)\n",
    "    acc_train_adv  = accuracy(model, trainloader, adversarial=True, epsilon=EPSILON)\n",
    "\n",
    "    conf_test_clean = mean_confidence_on_errors(model, testloader, adversarial=False)\n",
    "    conf_test_adv   = mean_confidence_on_errors(model, testloader, adversarial=True, epsilon=EPSILON)\n",
    "    conf_train_adv  = mean_confidence_on_errors(model, trainloader, adversarial=True, epsilon=EPSILON)\n",
    "\n",
    "    print(\"\\n--- RÃ©sultats Maxout CIFAR-10 ---\")\n",
    "    print(f\"Accuracy Test Clean   : {acc_test_clean:.2f}%\")\n",
    "    print(f\"Accuracy Test FGSM    : {acc_test_adv:.2f}%\")\n",
    "    print(f\"Accuracy Train FGSM   : {acc_train_adv:.2f}%\\n\")\n",
    "\n",
    "    print(\"--- Confiance moyenne sur les erreurs ---\")\n",
    "    print(f\"Confiance erreurs Test Clean : {conf_test_clean*100:.2f}%\")\n",
    "    print(f\"Confiance erreurs Test FGSM  : {conf_test_adv*100:.2f}%\")\n",
    "    print(f\"Confiance erreurs Train FGSM : {conf_train_adv*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add1c996-accb-4460-b074-33949831ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "EntraÃ®nement sur cuda\n",
      "Epoch [1/70] | Loss 1.397 | Acc 49.99%\n",
      "Epoch [2/70] | Loss 1.005 | Acc 64.86%\n",
      "Epoch [3/70] | Loss 0.875 | Acc 69.43%\n",
      "Epoch [4/70] | Loss 0.801 | Acc 71.85%\n",
      "Epoch [5/70] | Loss 0.747 | Acc 74.19%\n",
      "Epoch [6/70] | Loss 0.707 | Acc 75.56%\n",
      "Epoch [7/70] | Loss 0.668 | Acc 76.71%\n",
      "Epoch [8/70] | Loss 0.655 | Acc 77.20%\n",
      "Epoch [9/70] | Loss 0.622 | Acc 78.48%\n",
      "Epoch [10/70] | Loss 0.613 | Acc 78.79%\n",
      "Epoch [11/70] | Loss 0.595 | Acc 79.38%\n",
      "Epoch [12/70] | Loss 0.582 | Acc 79.70%\n",
      "Epoch [13/70] | Loss 0.570 | Acc 80.11%\n",
      "Epoch [14/70] | Loss 0.553 | Acc 80.74%\n",
      "Epoch [15/70] | Loss 0.547 | Acc 81.14%\n",
      "Epoch [16/70] | Loss 0.536 | Acc 81.25%\n",
      "Epoch [17/70] | Loss 0.534 | Acc 81.33%\n",
      "Epoch [18/70] | Loss 0.522 | Acc 81.90%\n",
      "Epoch [19/70] | Loss 0.511 | Acc 82.50%\n",
      "Epoch [20/70] | Loss 0.506 | Acc 82.15%\n",
      "Epoch [21/70] | Loss 0.500 | Acc 82.63%\n",
      "Epoch [22/70] | Loss 0.492 | Acc 82.93%\n",
      "Epoch [23/70] | Loss 0.488 | Acc 82.94%\n",
      "Epoch [24/70] | Loss 0.479 | Acc 83.23%\n",
      "Epoch [25/70] | Loss 0.485 | Acc 83.11%\n",
      "Epoch [26/70] | Loss 0.474 | Acc 83.60%\n",
      "Epoch [27/70] | Loss 0.473 | Acc 83.39%\n",
      "Epoch [28/70] | Loss 0.466 | Acc 83.77%\n",
      "Epoch [29/70] | Loss 0.468 | Acc 83.66%\n",
      "Epoch [30/70] | Loss 0.467 | Acc 83.73%\n",
      "Epoch [31/70] | Loss 0.452 | Acc 84.24%\n",
      "Epoch [32/70] | Loss 0.451 | Acc 84.28%\n",
      "Epoch [33/70] | Loss 0.452 | Acc 84.34%\n",
      "Epoch [34/70] | Loss 0.450 | Acc 84.20%\n",
      "Epoch [35/70] | Loss 0.445 | Acc 84.55%\n",
      "Epoch [36/70] | Loss 0.442 | Acc 84.56%\n",
      "Epoch [37/70] | Loss 0.435 | Acc 84.82%\n",
      "Epoch [38/70] | Loss 0.442 | Acc 84.72%\n",
      "Epoch [39/70] | Loss 0.430 | Acc 84.88%\n",
      "Epoch [40/70] | Loss 0.434 | Acc 84.68%\n",
      "Epoch [41/70] | Loss 0.434 | Acc 84.77%\n",
      "Epoch [42/70] | Loss 0.434 | Acc 84.98%\n",
      "Epoch [43/70] | Loss 0.419 | Acc 85.49%\n",
      "Epoch [44/70] | Loss 0.423 | Acc 85.24%\n",
      "Epoch [45/70] | Loss 0.424 | Acc 85.19%\n",
      "Epoch [46/70] | Loss 0.413 | Acc 85.73%\n",
      "Epoch [47/70] | Loss 0.417 | Acc 85.31%\n",
      "Epoch [48/70] | Loss 0.415 | Acc 85.62%\n",
      "Epoch [49/70] | Loss 0.415 | Acc 85.57%\n",
      "Epoch [50/70] | Loss 0.412 | Acc 85.65%\n",
      "Epoch [51/70] | Loss 0.410 | Acc 85.64%\n",
      "Epoch [52/70] | Loss 0.401 | Acc 85.96%\n",
      "Epoch [53/70] | Loss 0.407 | Acc 85.65%\n",
      "Epoch [54/70] | Loss 0.403 | Acc 86.02%\n",
      "Epoch [55/70] | Loss 0.398 | Acc 86.26%\n",
      "Epoch [56/70] | Loss 0.401 | Acc 86.00%\n",
      "Epoch [57/70] | Loss 0.403 | Acc 86.04%\n",
      "Epoch [58/70] | Loss 0.394 | Acc 86.21%\n",
      "Epoch [59/70] | Loss 0.394 | Acc 86.18%\n",
      "Epoch [60/70] | Loss 0.391 | Acc 86.20%\n",
      "Epoch [61/70] | Loss 0.399 | Acc 86.11%\n",
      "Epoch [62/70] | Loss 0.396 | Acc 86.26%\n",
      "Epoch [63/70] | Loss 0.396 | Acc 86.29%\n",
      "Epoch [64/70] | Loss 0.398 | Acc 85.93%\n",
      "Epoch [65/70] | Loss 0.386 | Acc 86.44%\n",
      "Epoch [66/70] | Loss 0.385 | Acc 86.68%\n",
      "Epoch [67/70] | Loss 0.390 | Acc 86.38%\n",
      "Epoch [68/70] | Loss 0.387 | Acc 86.56%\n",
      "Epoch [69/70] | Loss 0.381 | Acc 86.88%\n",
      "Epoch [70/70] | Loss 0.382 | Acc 86.69%\n",
      "\n",
      "--- RÃ©sultats Maxout CIFAR-10 ---\n",
      "Accuracy Test Clean   : 84.58%\n",
      "Accuracy Test FGSM    : 1.36%\n",
      "Accuracy Train FGSM   : 1.31%\n",
      "\n",
      "--- Confiance moyenne sur les erreurs ---\n",
      "Confiance erreurs Test Clean : 69.38%\n",
      "Confiance erreurs Test FGSM  : 88.50%\n",
      "Confiance erreurs Train FGSM : 88.04%\n"
     ]
    }
   ],
   "source": [
    "#Optimizer Adam\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 70\n",
    "EPSILON = 0.1\n",
    "\n",
    "# maxout conv\n",
    "class MaxoutConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k=2, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * k,\n",
    "                              kernel_size=kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.view(b, self.out_channels, self.k, h, w)\n",
    "        x, _ = x.max(dim=2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RealConvMaxoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = MaxoutConv2d(3, 48, k=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv2 = MaxoutConv2d(48, 96, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.drop2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.conv3 = MaxoutConv2d(96, 192, k=2)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.drop3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc = nn.Linear(192 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.pool1(self.conv1(x)))\n",
    "        x = self.drop2(self.pool2(self.conv2(x)))\n",
    "        x = self.drop3(self.pool3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# cifar-10\n",
    "def load_data():\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                            shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# training\n",
    "def train(model, trainloader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    print(f\"EntraÃ®nement sur {DEVICE}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, running_loss = 0, 0, 0.0\n",
    "\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss {running_loss/len(trainloader):.3f} | Acc {acc:.2f}%\")\n",
    "\n",
    "# FGSM\n",
    "def fgsm_attack(x, epsilon, grad):\n",
    "    return x + epsilon * grad.sign()\n",
    "\n",
    "# Ã©valuation\n",
    "def mean_confidence_on_errors(model, dataloader, adversarial=False, epsilon=0.0):\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        if adversarial:\n",
    "            inputs.requires_grad = True\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            grad = inputs.grad.data\n",
    "            inputs = fgsm_attack(inputs, epsilon, grad)\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        mask = preds != labels\n",
    "        if mask.any():\n",
    "            confidences.extend(probs[mask, preds[mask]].detach().cpu().numpy())\n",
    "\n",
    "    if len(confidences) == 0:\n",
    "        return 0.0\n",
    "    return float(np.mean(confidences))\n",
    "\n",
    "# prÃ©cision\n",
    "def accuracy(model, dataloader, adversarial=False, epsilon=0.0):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        if adversarial:\n",
    "            inputs.requires_grad = True\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            inputs = fgsm_attack(inputs, epsilon, inputs.grad.data)\n",
    "            outputs = model(inputs)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return 100. * correct / total\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    trainloader, testloader = load_data()\n",
    "\n",
    "    model = RealConvMaxoutNet().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ðŸ” CHANGEMENT ICI : SGD â†’ Adam\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    train(model, trainloader, optimizer, criterion, EPOCHS)\n",
    "\n",
    "    acc_test_clean = accuracy(model, testloader, adversarial=False)\n",
    "    acc_test_adv   = accuracy(model, testloader, adversarial=True, epsilon=EPSILON)\n",
    "    acc_train_adv  = accuracy(model, trainloader, adversarial=True, epsilon=EPSILON)\n",
    "\n",
    "    conf_test_clean = mean_confidence_on_errors(model, testloader, adversarial=False)\n",
    "    conf_test_adv   = mean_confidence_on_errors(model, testloader, adversarial=True, epsilon=EPSILON)\n",
    "    conf_train_adv  = mean_confidence_on_errors(model, trainloader, adversarial=True, epsilon=EPSILON)\n",
    "\n",
    "    print(\"\\n--- RÃ©sultats Maxout CIFAR-10 ---\")\n",
    "    print(f\"Accuracy Test Clean   : {acc_test_clean:.2f}%\")\n",
    "    print(f\"Accuracy Test FGSM    : {acc_test_adv:.2f}%\")\n",
    "    print(f\"Accuracy Train FGSM   : {acc_train_adv:.2f}%\\n\")\n",
    "\n",
    "    print(\"--- Confiance moyenne sur les erreurs ---\")\n",
    "    print(f\"Confiance erreurs Test Clean : {conf_test_clean*100:.2f}%\")\n",
    "    print(f\"Confiance erreurs Test FGSM  : {conf_test_adv*100:.2f}%\")\n",
    "    print(f\"Confiance erreurs Train FGSM : {conf_train_adv*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9aabfc-1400-485c-a9f3-b9d0613a8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test sur Rubbish Examples\n",
    "#GÃ©nÃ©ration de 10 000 Ã©chantillons avec du bruit gaussien\n",
    "#Evaluation sur le rÃ©seau convnet entrainÃ© au dessus (optimizer SGD executÃ© en dernier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f843cf40-50d8-4a9e-801b-16e30e22ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rubbish Class Test (N(0, I_{3Ã—32Ã—32}), 1000 samples) ---\n",
      "----------------------------------------------------------------------------------\n",
      "Nombre d'Ã©chantillons           : 1000\n",
      "Taux de prÃ©dictions > 0.5       : 99.70%\n",
      "Confiance moyenne (sur erreurs) : 97.60%\n",
      "----------------------------------------------------------------------------------\n",
      "Stats des probabilitÃ©s softmax (rubbish inputs):\n",
      "  Min  : 0.0000\n",
      "  Mean : 0.1000\n",
      "  Max  : 1.0000\n",
      "Fraction de probs > 0.5 par classe :\n",
      "[0.        0.        0.028     0.002     0.        0.        0.9480001\n",
      " 0.        0.        0.019    ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Rubbish Class Test (N(0, I_{3Ã—32Ã—32}), 1000 samples) ---\")\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# Bruit gaussien CIFAR-10 : (N, 3, 32, 32)\n",
    "rubbish_noise = torch.randn(num_samples, 3, 32, 32).to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(rubbish_noise)          # logits\n",
    "    probs = torch.softmax(outputs, dim=1)   # probabilitÃ©s\n",
    "    confs, preds = probs.max(dim=1)         # confiance max par Ã©chantillon\n",
    "\n",
    "# Une prÃ©diction est considÃ©rÃ©e \"fausse\" si la confiance est Ã©levÃ©e (> 0.5)\n",
    "errors = confs > 0.5\n",
    "error_rate = errors.float().mean().item() * 100\n",
    "\n",
    "# Confiance moyenne sur ces erreurs\n",
    "avg_conf_errors = confs[errors].mean().item() * 100 if errors.any() else 0.0\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(f\"Nombre d'Ã©chantillons           : {num_samples}\")\n",
    "print(f\"Taux de prÃ©dictions > 0.5       : {error_rate:.2f}%\")\n",
    "print(f\"Confiance moyenne (sur erreurs) : {avg_conf_errors:.2f}%\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "\n",
    "# Diagnostics utiles (sanity check)\n",
    "print(\"Stats des probabilitÃ©s softmax (rubbish inputs):\")\n",
    "print(f\"  Min  : {probs.min().item():.4f}\")\n",
    "print(f\"  Mean : {probs.mean().item():.4f}\")\n",
    "print(f\"  Max  : {probs.max().item():.4f}\")\n",
    "\n",
    "print(\"Fraction de probs > 0.5 par classe :\")\n",
    "print((probs > 0.5).float().mean(dim=0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8b875-383f-485f-869c-7f87523ea06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
